---
title: "I understand multiple regression"
category: "Statistics Bootcamp"
module: 13
order: 3
---

# I understand multiple regression

> ğŸ“š **Overview:** Extend regression to multiple predictorsâ€”controlling for confounders.

Regression with multiple predictors.

---

## Learning Objectives

After completing this section, you will be able to:
- Understand multiple regression model
- Interpret coefficients as partial effects
- Know about adjusted RÂ²

---

## Intuition (why multiple regression exists)

In business, outcomes usually depend on **more than one factor**. Multiple regression lets you estimate the relationship between \(Y\) and one predictor while **controlling for other predictors**.

The key phrase is **â€œholding other variables constantâ€**: it means â€œcompare two observations that are the same in all other included predictors, except \(x_j\).â€

**Why this matters (confounding):** If advertising spend rises in peak season, then a simple regression of Sales on Ads can mix up â€œads effectâ€ with â€œseason effectâ€. Adding a season variable helps separate these effects.

---

## When to use / when not to use

- **Use when**: you want to explain/predict a numeric outcome using **multiple predictors** (numeric or dummy-coded categorical).
- **Use when**: you expect confounding and want a â€œcontrolledâ€ comparison.
- **Do not use when**: the outcome is categorical (use logistic models; not covered here).
- **Do not use when**: the relationship is clearly non-linear and you have no transformation/terms to model it.

---

## Interpretation sentence templates (exam-ready)

For a coefficient on \(x_j\):

- â€œA one-unit increase in \(x_j\) is associated with an average change of **[Î²Ì‚â±¼]** in \(Y\), **holding the other predictors constant**.â€
- â€œThe sign of \(\\hat\\beta_j\) is [positive/negative], meaning higher \(x_j\) is associated with [higher/lower] \(Y\) after controlling for the other variables.â€

For adjusted RÂ²:

- â€œAdjusted \(R^2\) increases only if the new predictor improves the model enough to justify the extra complexity.â€

---

## Common traps (high-frequency)

> âš ï¸ **Trap 1: Forgetting â€˜holding others constantâ€™.**
> Multiple regression coefficients are *partial* effects, not simple pairwise relationships.

> âš ï¸ **Trap 2: Sign flips.**
> A coefficient can change sign after adding controls (classic confounding).

> âš ï¸ **Trap 3: Interpreting the intercept literally.**
> \(\\hat\\beta_0\) is the predicted \(Y\) when all predictors are 0 â€” often outside the meaningful data range.

> âš ï¸ **Trap 4: Multicollinearity.**
> If predictors move together strongly (e.g., Ads and Promo), individual coefficients can become unstable.

> âš ï¸ **Trap 5: Causality language.**
> Unless the study design supports it, write â€œassociated withâ€, not â€œcausesâ€.

## The Model

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \varepsilon
$$

Each $\beta_j$ represents the effect of $x_j$ **holding other variables constant**.

---

## Interpretation

**Example:**

$$
\hat{y} = 10 + 2x_1 + 5x_2
$$

- $\beta_1 = 2$: For each unit increase in xâ‚, y increases by 2, **holding xâ‚‚ constant**
- $\beta_2 = 5$: For each unit increase in xâ‚‚, y increases by 5, **holding xâ‚ constant**
- $\beta_0 = 10$: Predicted y when xâ‚ = xâ‚‚ = 0

---

## Adjusted RÂ²

Standard RÂ² always increases with more variables. **Adjusted RÂ²** penalizes for complexity:

$$
R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-k-1}
$$

Use adjusted RÂ² to compare models with different numbers of predictors.

---

## Practice Problem

Model: $\hat{\text{Sales}} = 100 + 3(\text{Ads}) + 2(\text{Price}) - 5(\text{Competitor})$

Interpret each coefficient.

<details>
<summary>ğŸ’¡ Show Solution</summary>

- **Intercept (100):** Predicted sales when all predictors are zero
- **Ads (3):** Each unit increase in advertising increases sales by 3, holding price and competitor constant
- **Price (2):** Each unit increase in price increases sales by 2 (counterintuitive - may indicate luxury good)
- **Competitor (-5):** Each unit of competitor activity decreases sales by 5

</details>

---

## Key Takeaways

- Multiple regression controls for confounders
- Coefficients are **partial effects**
- Use adjusted RÂ² for model comparison
- More variables â‰  better model

---

## Navigation

[â† Dummy Variables](dummy_variables.md) | [Module Index](index.md) | [Exercises â†’](../exercises/index.md)


