================================================================================
LECTURE 11: STATISTICS BOOTCAMP
Total Slides: 26
================================================================================

--- Slide 1 of 26 ---

Prof. Dr. Roland FÃ¼ss 
Swiss Institute of Banking and Finance (s/bf)
Methods: Statistics (4,120)
11. Linear Regression
Spring 2022


--- Slide 2 of 26 ---

Methods: Statistics (Spring 2022) 
Contents
I. Basic Idea
II. Correlation vs. Regression
III. Basic Model and Method of Ordinary Least Squares (OLS)
IV. Goodness of Fit
V. Properties of OLS Estimators
VI. Confidence Intervals and t-Tests for OLS Estimators
2


--- Slide 3 of 26 ---

Methods: Statistics (Spring 2022) 
Learning Objectives
After this lecture, you know how: 
â€¢ a linear regression analysis is performed and which conditions
must apply for a valid estimation.
â€¢ correlations in a data set can be investigated and interpreted by 
means of a regression analysis.
3


--- Slide 4 of 26 ---

Methods: Statistics (Spring 2022) 
Literature
Hill, R.C., W.E. Griffiths, and G.C. Lim (2011). Principles of Econometrics, 4th ed. 
United States: Wiley, Chapter 2.**
Levine, D.M., K. A. Szabat, and D.F. Stephan. (2016). Business Statistics: A First 
Course, 7th ed. United States: Pearson, Chapter 12.*
Stinerock, R. (2018). Statistics with R. United Kingdom: Sage. Chapter 12.
Shira, Joseph (2012). Statistische Methoden der VWL und BWL, 4th ed. Munich 
et al.: Pearson Studium, Chapter 17.
Weiers, R. M. (2011). Introductory Business Statistics,7th ed., Canada: Thomson 
South-Western, Chapter 15.
4
*Mandatory literature **Very recommendable


--- Slide 5 of 26 ---

Methods: Statistics (Spring 2022) 
I. Basic Idea
Regression analysis examines whether variables are related to each other and 
in which direction this relationship goes. It extends the analysis of variance and is 
often used for predictions in forecasts or choice models.
One examines whether the change of one variable (x) leads to a change of 
another variable (y) (causal relationship):
â€¢ xk = Independent variable, predictor variable (k = 1,2,...,K)
â€¢ y = Dependent variable, target variable
Regression analysis is divided according to the number of involved predictors:
â€¢ Simple Regression with K = 1
â€¢ Multiple Regression with K > 1
5


--- Slide 6 of 26 ---

Methods: Statistics (Spring 2022) 
II. Correlation vs. Regression
Correlation analysis:
The relationship between the metric variable x and the metric variable y is
investigated (non-directional relationship).
Regression analysis:
The influence of the metric or dummy-coded variable x
1 and possible further 
variables xk on the metric variable y is investigated (directional relationship).
6
x y
x1 y
xk


--- Slide 7 of 26 ---

Methods: Statistics (Spring 2022) 
II. Correlation vs. Regression
In contrast to correlation analysis, regression analysis allows the examination of
dependencies between two (or more) metrically scaled variables. (exception:
dummy-coded variables).
There is an assumed cause-effect relationship between x and y, where x is the
cause and y is the effect. Variable y is therefore dependent on variable x. This
relationship is described as follows:
y = f (x)
The reasoning for this cause-effect relationship is not derived from regression 
analysis but from theory (e.g., from an economic, behavioral theory).
7


--- Slide 8 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model (Introductory Example)
Income and food expenses:
An economic theory describes the relationship between the weekly income and
food expenditure of students. With the help of a regression analysis, the strength
and form of this relationship could be determined. The following questions,
among others, should be clarified:
â€¢ Is there a significant relationship between income and food expenditure?
â€¢ Can the variance in weekly income explain the variance in food expenditure?
â€¢ How do food expenses increase when the weekly income rises by 100 CHF?
â€¢ What food expenses should a student with a weekly income of 500 CHF have?
8


--- Slide 9 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model (Introductory Example)
Consider the relationship between x = income and y = food expenditure per week. 
The chart below shows the probability distribution of food expenses for students
with an income of x = 1000 CHF.
9
ğœ‡ğœ‡ğ‘¦ğ‘¦|1000
ğ‘¦ğ‘¦
ğ‘“ğ‘“(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)
 ğ‘“ğ‘“(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 1000)
ğœ‡ğœ‡ğ‘¦ğ‘¦|ğ‘¥ğ‘¥=1000 = ğ¸ğ¸[ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 1000]


--- Slide 10 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model (Introductory Example)
Our economic theory tells us that the average weekly food expenditure increases 
with income!
10
ğœ‡ğœ‡ğ‘¦ğ‘¦|1000
ğ‘¦ğ‘¦
ğ‘“ğ‘“(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)
ğ‘“ğ‘“(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 1000)
ğœ‡ğœ‡ğ‘¦ğ‘¦|2000
ğ‘“ğ‘“(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 2000)
ğœ‡ğœ‡ğ‘¦ğ‘¦|ğ‘¥ğ‘¥=1000 = ğ¸ğ¸[ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 1000] ğœ‡ğœ‡ğ‘¦ğ‘¦|ğ‘¥ğ‘¥=2000 = ğ¸ğ¸[ğ‘¦ğ‘¦|ğ‘¥ğ‘¥ = 2000]


--- Slide 11 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model (Introductory Example)
If there is a linear relationship between income and food expenditure per week, 
the true regression model can be drawn as follows:
11
ğ¼ğ¼ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›ğ‘›
ğ‘¥ğ‘¥
ğ¸ğ¸(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)âˆ…ğ¹ğ¹ğ‘›ğ‘›ğ‘›ğ‘›ğ‘œğ‘œ ğ¸ğ¸ğ‘¥ğ‘¥ğ¸ğ¸ğ‘›ğ‘›ğ‘›ğ‘›ğ‘œğ‘œğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘›ğ‘›
ğ›½ğ›½1
ğ›½ğ›½2 =
âˆ†ğ¸ğ¸(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)
âˆ†ğ‘¥ğ‘¥ =
ğ‘‘ğ‘‘ğ¸ğ¸(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)
ğ‘‘ğ‘‘ğ‘¥ğ‘¥
ğ¸ğ¸ ğ‘¦ğ‘¦ ğ‘¥ğ‘¥ = ğ›½ğ›½1 + ğ›½ğ›½2ğ‘¥ğ‘¥
Î”ğ¸ğ¸(ğ‘¦ğ‘¦|ğ‘¥ğ‘¥)
Î”ğ‘¥ğ‘¥


--- Slide 12 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model (Introductory Example)
The "complete picture" of the true model looks like this:
12
ğ‘¥ğ‘¥
f(ğ‘¦ğ‘¦)
ğ¸ğ¸ ğ‘¦ğ‘¦ ğ‘¥ğ‘¥ = ğ›½ğ›½1 + ğ›½ğ›½2ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğœ‡ğœ‡ğ‘¦ğ‘¦|1000 ğœ‡ğœ‡ğ‘¦ğ‘¦|2000
ğ‘¥ğ‘¥ = 1000
ğ‘¥ğ‘¥ = 2000


--- Slide 13 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model
The random error in this regression model is given as :
ğ‘›ğ‘›ğ‘–ğ‘– = ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ğ¸ğ¸ ğ‘¦ğ‘¦ğ‘–ğ‘– ğ‘¥ğ‘¥ğ‘–ğ‘– = ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ğ›½ğ›½1âˆ’ğ›½ğ›½2ğ‘¥ğ‘¥ğ‘–ğ‘–
This results in the following assumptions and the simple linear regression model 
can be written as follows:
â€¢ Assumption 1:     ğ‘¦ğ‘¦ğ‘–ğ‘– = ğ›½ğ›½1+ ğ›½ğ›½2ğ‘¥ğ‘¥ğ‘–ğ‘– + ğ‘›ğ‘›ğ‘–ğ‘–
â€¢ Assumption 2:     ğ¸ğ¸ ğ‘›ğ‘›ğ‘–ğ‘– ğ‘¥ğ‘¥ğ‘–ğ‘– = 0
â€¢ Assumption 3:     Var(ğ‘›ğ‘›ğ‘–ğ‘–|ğ‘¥ğ‘¥ğ‘–ğ‘–) = ğœğœ2
â€¢ Assumption 4:     Cov ğ‘›ğ‘›ğ‘–ğ‘–, ğ‘›ğ‘›ğ‘—ğ‘— ğ‘¥ğ‘¥ğ‘–ğ‘–, ğ‘¥ğ‘¥ğ‘—ğ‘— = 0 for ğ¸ğ¸ â‰  ğ‘—ğ‘—
â€¢ Assumption 5:     ğ‘¥ğ‘¥ğ‘–ğ‘–, â€¦ , ğ‘¥ğ‘¥ğ‘›ğ‘› are random and not all the same.
â€¢ Assumption 6:     ğ‘›ğ‘›ğ‘–ğ‘–, â€¦ , ğ‘›ğ‘›ğ‘›ğ‘› are normally distributed.
13


--- Slide 14 of 26 ---

Methods: Statistics (Spring 2022) 
III. Basic Model
Hence, the relationship between ğ‘¦ğ‘¦ğ‘–ğ‘–, ğ‘›ğ‘›ğ‘–ğ‘– and the true regression line (population
regression line) is as follows:
14
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğ¸ğ¸ ğ‘¦ğ‘¦ ğ‘¥ğ‘¥ = ğ›½ğ›½1 + ğ›½ğ›½2ğ‘¥ğ‘¥
ğ‘¦ğ‘¦4
ğ‘¦ğ‘¦3
ğ‘¦ğ‘¦2
ğ‘¦ğ‘¦1
ğ‘¥ğ‘¥1 ğ‘¥ğ‘¥4ğ‘¥ğ‘¥3ğ‘¥ğ‘¥2
ğ‘›ğ‘›1
ğ‘›ğ‘›2
ğ‘›ğ‘›3
ğ‘›ğ‘›4


--- Slide 15 of 26 ---

Methods: Statistics (Spring 2022) 
III. Method of Ordinary Least Squares (OLS)
The Ordinary Least Squares method tries to find the true regression line. The 
estimated line has the smallest distance to the individual observations.
15
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– = ğ‘ğ‘1 + ğ‘ğ‘2ğ‘¥ğ‘¥
ğ‘¦ğ‘¦4
ğ‘¦ğ‘¦3
ğ‘¦ğ‘¦2
ğ‘¦ğ‘¦1
ğ‘¥ğ‘¥1 ğ‘¥ğ‘¥4ğ‘¥ğ‘¥3ğ‘¥ğ‘¥2
Ãª2
ï¿½ğ‘¦ğ‘¦2


--- Slide 16 of 26 ---

Methods: Statistics (Spring 2022) 
III. Method of Ordinary Least Squares (OLS)
Mathematically, the OLS estimates ğ‘ğ‘1 and ğ‘ğ‘2 for the constant and the slope of the 
true regression model are based on the OLS residuals.
True regression model: ğ¸ğ¸ ğ‘¦ğ‘¦ ğ‘¥ğ‘¥ = ğ›½ğ›½1 + ğ›½ğ›½2ğ‘¥ğ‘¥
Estimated regression model: ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– = ğ‘ğ‘1 + ğ‘ğ‘2ğ‘¥ğ‘¥
OLS residuals: Ì‚ğ‘›ğ‘›ğ‘–ğ‘– = ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– = ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ğ‘ğ‘1âˆ’ğ‘ğ‘2ğ‘¥ğ‘¥ğ‘–ğ‘–
The residual sum of squares is minimized. The sum of squares is used because 
the residuals can be positive or negative.
ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›
Ì‚ğ‘›ğ‘›ğ‘–ğ‘–
2 = ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›
(ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ğ‘ğ‘1 âˆ’ğ‘ğ‘2ğ‘¥ğ‘¥ğ‘–ğ‘–)2
Solving the first-order conditions for a minimum yields:
16
ğ‘ğ‘1 = ï¿½ğ‘¦ğ‘¦âˆ’ ğ‘ğ‘2 Ì…ğ‘¥ğ‘¥ ğ‘ğ‘2 = ğ‘›ğ‘›âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’(âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–)(âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¦ğ‘¦ğ‘–ğ‘–)
ğ‘›ğ‘›âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–2 âˆ’(âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–)2


--- Slide 17 of 26 ---

Methods: Statistics (Spring 2022) 
III. OLS (Introductory Example, R-Example 1)
In order to investigate the theoretical relationship between the weekly income and 
the food expenditure of students, a sample is collected at the HSG. 40 students
state their income and food expenses per week.
17
Student Food expenditure (CHF) Income (CHF100)
i yi xi
1 115.22 3.69
2 135.98 4.39
â€¦ â€¦ â€¦
39 257.95 29.40
40 375.73 33.40
Descriptive statistics
Mean 283.574 19.605
Median 264.480 20.030
Max. 587.660 33.400
Min. 109.710 3.690
SDV 112.675 6.848


--- Slide 18 of 26 ---

Methods: Statistics (Spring 2022) 
III OLS (Introductory Example, R-Example 1)
Open the file "L11-Example_1.R" in R-Studio and reproduce the R-code and 
interpret the following regression line.
18
ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– = 83.42 + 10.21ğ‘¥ğ‘¥


--- Slide 19 of 26 ---

Methods: Statistics (Spring 2022) 
IV. Goodness of Fit
However, the question arises as to how well the OLS estimate resembles the true 
regression line. The variance decomposition gives an indication:
Total Sum of Squares (SST) = Regression Sum of Squares (SSR) + Residual Sum of Squares (SSE)
ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›
(ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦) 2 = ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›
( ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦) 2 + ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›
(ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘–) 2
19
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– = ğ‘ğ‘1 + ğ‘ğ‘2ğ‘¥ğ‘¥
ğ‘¦ğ‘¦ğ‘–ğ‘–
ï¿½ğ‘¦ğ‘¦
ğ‘¥ğ‘¥ğ‘–ğ‘–
ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘–
ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘–
ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦
ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦


--- Slide 20 of 26 ---

Methods: Statistics (Spring 2022) 
IV. Goodness of Fit
Based on the variance decomposition, the coefficient of determination R2
measures the proportion of the variation in the dependent variable that is explained
by the regression model. R2 only assumes values between 0 and 1.
The coefficient of determination R2 can be interpreted as the share of dispersion
of the y-values that is explained by the regression. For example, the R2 = 0.37
in the previous regression means that 37% of the dispersion in weekly food
expenditures of students can be explained by the linear dependency on income.
20
ğ‘…ğ‘…2 = SSR
SST


--- Slide 21 of 26 ---

Methods: Statistics (Spring 2022) 
IV. Goodness of Fit
These four graphs illustrate possible values for the coefficient of determination R2: 
21
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğ‘¥ğ‘¥
ğ‘¦ğ‘¦
ğ‘…ğ‘…2 = 1 0 < ğ‘…ğ‘…2 < 1
0 < ğ‘…ğ‘…2 < 1ğ‘…ğ‘…2 =0


--- Slide 22 of 26 ---

Methods: Statistics (Spring 2022) 
IV. Goodness of Fit
To check whether the regression model is significant overall, an F-test* can be
used. This test checks whether the prediction of the dependent variable is improved
by adding the independent variable (ğ»ğ»0: ğ›½ğ›½2 = 0, slope test). Hence, it clarifies
whether the model as a whole has explanatory power.
Mean Square Regression:
Mean Square Error: 
The calculated F-Ratio is then compared with the critical value Fc, which follows an 
F-distribution with 1 and n - 2 degrees of freedom. If the F-Ratio exceeds the critical 
value, the model is significant and the linear relationship can be confirmed.
22
ğ‘€ğ‘€ğ‘€ğ‘€ğ¸ğ¸ = SSE
n âˆ’2
ğ‘€ğ‘€ğ‘€ğ‘€ğ‘…ğ‘… = SSR
1 F-Ratio = MSR
MSE
* The results of a t-test and a F-test are identical for a simple regression. 
The F-test in case of multiple regression will be covered in the next lecture.


--- Slide 23 of 26 ---

Methods: Statistics (Spring 2022) 
V. Properties of OLS Estimators
The OLS estimators are random variables with means and variances. If
assumptions 1 to 5 hold, then the following applies:
ğ¸ğ¸(ğ‘ğ‘1) = ğ›½ğ›½1 Var(ğ‘ğ‘1) =
ğœğœ2 âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–
2
ğ‘›ğ‘›âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¥ğ‘¥ğ‘–ğ‘–âˆ’ Ì…ğ‘¥ğ‘¥)2
ğ¸ğ¸(ğ‘ğ‘2) = ğ›½ğ›½2 Var(ğ‘ğ‘2) =
ğœğœ2
âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¥ğ‘¥ğ‘–ğ‘–âˆ’ Ì…ğ‘¥ğ‘¥)2
and Cov ğ‘ğ‘1, ğ‘ğ‘2 = ğœğœ2[ âˆ’ Ì…ğ‘¥ğ‘¥
âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¥ğ‘¥ğ‘–ğ‘–âˆ’ Ì…ğ‘¥ğ‘¥)2]
According to the Gauss-Markov Theorem, this means that the OLS estimators
ğ‘ğ‘1 and ğ‘ğ‘2 have the smallest variance of all linear and unbiased estimators of ğ›½ğ›½1
and ğ›½ğ›½2. They are BLUE (Best Linear Unbiased Estimators).
The Gauss-Markov Theorem does not depend on assumption 6. If assumption 6 
does happen to hold, the OLS estimators are also normally distributed.
23


--- Slide 24 of 26 ---

Methods: Statistics (Spring 2022) 
V. Variance of OLS estimators
In practice, the error variance is unknown, which means the variances of the
OLS estimators are also unknown. An unbiased estimator of the error variance is
given as follows:
ï¿½ğœğœ2 = âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¦ğ‘¦ğ‘–ğ‘– âˆ’ ï¿½ğ‘¦ğ‘¦ğ‘–ğ‘–)2
ğ‘›ğ‘›âˆ’2 = âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› Ì‚ğ‘›ğ‘›ğ‘–ğ‘–
2
ğ‘›ğ‘›âˆ’2
Therefore, the estimated variances of the OLS estimators are:
ï¿½Var(ğ‘ğ‘1) =
ï¿½ğœğœ2 âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› ğ‘¥ğ‘¥ğ‘–ğ‘–
2
ğ‘›ğ‘›âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¥ğ‘¥ğ‘–ğ‘–âˆ’ Ì…ğ‘¥ğ‘¥)2
ï¿½Var(ğ‘ğ‘2) =
ï¿½ğœğœ2
âˆ‘ğ‘–ğ‘–=1
ğ‘›ğ‘› (ğ‘¥ğ‘¥ğ‘–ğ‘–âˆ’ Ì…ğ‘¥ğ‘¥)2
The square roots of the estimated variances are called the standard errors.
24


--- Slide 25 of 26 ---

Methods: Statistics (Spring 2022) 
VI. Confidence Intervals and t-Tests for OLS Estimators
If assumptions 1 to 6 are met, confidence intervals for the OLS estimators can be 
calculated as follows:
ğ¸ğ¸ = ğ‘ğ‘ğ‘˜ğ‘˜âˆ’ğ›½ğ›½ğ‘˜ğ‘˜
ğ‘ ğ‘ ğ‘ğ‘ğ‘˜ğ‘˜
âˆ¼ ğ¸ğ¸ğ‘›ğ‘›âˆ’2 for k= 1, 2
ğ‘ğ‘ğ‘˜ğ‘˜ Â± ğ¸ğ¸ğ‘ğ‘ğ‘ ğ‘ ğ‘ğ‘ğ‘˜ğ‘˜
The critical value ğ¸ğ¸ğ‘ğ‘ is determined based on the significance level Î± and can be
found in the table of the t-distribution. It should be pointed out that we have ğ‘›ğ‘›âˆ’2
degrees of freedom, which is the sample size minus the total number of
independent variables minus 1.
It is also possible to create one-tailed and two-tailed t-tests for the OLS
estimators with the t-statistics stated above. The procedure of hypothesis testing
remains the same as in the previous lectures.
25


--- Slide 26 of 26 ---

Methods: Statistics (Spring 2022) 
VI. OLS Estimator (Introductory Example, R-Example 1)
Open the file "L11-Example_1.R" in R-Studio and reproduce the R-Code, which 
leads to the following results.
26

